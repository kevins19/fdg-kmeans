{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNYYKIWOZvcEmedLttPHPzQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"YRA4zO_2pgIi"},"outputs":[],"source":["# FOR RUNNING PURPOSES ONLY - FIXED SEED THROUGHOUT\n","\n","import sklearn\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import math\n","import random\n","\n","from sklearn.cluster import KMeans\n","from sklearn import metrics\n","\n","# DATA PROCESSING\n","\n","header = open('Iris.csv').readlines()[0].strip().split(',')[1:-1]\n","classes = {'Iris-setosa':0, 'Iris-versicolor':1, 'Iris-virginica':2}\n","temp = np.array(pd.read_csv('Iris.csv'))\n","x = temp[:, 1:-1]\n","y = temp[:, -1]\n","\n","N = len(x)\n","M = len(header)\n","\n","random.seed(278034)\n","\n","# DATA EVALUATION\n","# Creating the similarity matrix, adj\n","# Only edges with a similarity that passes the density threshold will be considered to maintain sparsity of the graph\n","\n","adj = [[0 for j in range(N)] for i in range(N)]\n","mn = x.min(axis = 0)\n","mx = x.max(axis = 0)\n","\n","ed = []\n","density = 0.15\n","P = 30\n","\n","adj_list = []\n","\n","for i in range(N):\n","  for j in range(i+1, N):\n","    sm = 0\n","    for h in range(1, M):\n","      da = (x[i][h] - mn[h]) / (mx[h] - mn[h])\n","      db = (x[j][h] - mn[h]) / (mx[h] - mn[h])\n","      sm += abs(da - db)\n","    sm /= (M - 1)\n","    ed.append((sm, i, j))\n","\n","ed.sort()\n","\n","for i in range(int(density * (N * (N-1) / 2))):\n","    # print(1 - ed[i][0])\n","    adj[ed[i][1]][ed[i][2]] = 1 - ed[i][0]\n","    adj[ed[i][2]][ed[i][1]] = 1 - ed[i][0]\n","    adj_list.append([ed[i][1], ed[i][2]])\n","\n","for i in range(int(density * (N * (N-1) / 2)), len(ed)):\n","  if random.random() < density/P:\n","    adj[ed[i][1]][ed[i][2]] = (1 - ed[i][0])\n","    adj[ed[i][2]][ed[i][1]] = (1 - ed[i][0])\n","    adj_list.append([ed[i][1], ed[i][2]])\n","\n","\n","# building random points\n","\n","og_x = []\n","og_y = []\n","\n","for i in range(N):\n","  og_x.append((random.random() - 0.5) * 100);\n","  og_y.append((random.random() - 0.5) * 100);\n","\n","\n","# FORCE-DIRECTED GRAPH MODEL\n","\n","# CONSTANT VARIABLES (to be adjusted for experimentation)\n","# alpha = 1\n","# a_decay = 0.1\n","delta_t = 0.01\n","iterations = 200\n","\n","class Node:\n","  def __init__(self, id, x = 0, y = 0, vx = 0, vy = 0, fx = 0, fy = 0):\n","    self.id = id\n","    self.x = x\n","    self.y = y\n","    self.vx = vx\n","    self.vy = vy\n","    self.fx = fx\n","    self.fy = fy\n","\n","\n","  def base_position_recalculation(self):\n","    # treat fx and fy as displacement\n","\n","    # update position by adding on displacement vector\n","    self.x += self.fx * delta_t\n","    self.y += self.fy * delta_t\n","    self.fx = 0\n","    self.fy = 0 \n","\n","def Gravity(x, y):\n","  c = 0.1\n","  xfac = 1\n","  if x < 0:\n","    xfac = -1\n","  yfac = 1\n","  if y < 0:\n","    yfac = -1\n","  return (-c * x * x * xfac, -c * y * y * yfac)\n","\n","def Linear_Attraction(dx, dy, k):\n","  c = 1\n","  mag_d = math.sqrt(dx * dx + dy * dy)\n","  return (c * k * dx * dx / mag_d, c * k* dy * dy / mag_d)\n","\n","\n","def Eades_Logarithmic_Attraction(dx, dy, k):\n","  c = 0.1 # experiment with c\n","  mag_d = math.sqrt(dx * dx + dy * dy)\n","  if mag_d == 0:\n","    return (0, 0)\n","  return (k * math.log2(mag_d/c) * dx / mag_d, \n","          k * math.log2(mag_d/c) * dy / mag_d)\n","\n","def Inverse_Square_Repulsion(dx, dy, k):\n","  c = 10 # experiment with c\n","  mag_d = math.sqrt(dx * dx + dy * dy)\n","  d = max(mag_d, 1);\n","  val = c / (d * d)\n","  return (- val * dx / mag_d, - val * dy / mag_d)\n","\n","def Standard_Force_Directed_Graph(attract, repulse, gravity):\n","\n","  nodes = [Node(i) for i in range(N)]\n","  for i in range(N):\n","    nodes[i].x = og_x[i]\n","    nodes[i].y = og_y[i]\n","\n","\n","  for i in range(iterations):\n","    for u in range(N):\n","      for v in range(N):\n","        if u == v:\n","          continue\n","        dx = nodes[v].x - nodes[u].x\n","        dy = nodes[v].y - nodes[u].y\n","        if(adj[u][v] > 0):\n","          af = attract(dx, dy, adj[u][v])\n","          nodes[u].fx += af[0]\n","          nodes[u].fy += af[1]\n","        rf = repulse(dx, dy, 0)\n","        nodes[u].fx += rf[0]\n","        nodes[u].fy += rf[1]\n","      gf = gravity(nodes[u].x, nodes[u].y)\n","      nodes[u].fx += gf[0]\n","      nodes[u].fy += gf[1]\n","\n","    for u in range(N):\n","      nodes[u].base_position_recalculation()\n","\n","  return nodes\n","\n","# def Fruchterman_Reingold_algorithm():\n","# def LinLog_algorithm():\n","\n","test_1 = Standard_Force_Directed_Graph(Eades_Logarithmic_Attraction, Inverse_Square_Repulsion, Gravity)\n","\n","pos_1 = [[test_1[i].x, test_1[i].y] for i in range(N)]\n","\n","\n","\n","# VISUALISATION SECTION\n","\n","node_list = pos_1\n","adj_list = []\n","for i in range(N):\n","  for j in range(i+1, N):\n","    if(adj[i][j] > 0):\n","      adj_list.append([i, j])\n","\n","\n","\n","dlist = np.array(node_list)\n","kmeans = KMeans(n_clusters=3).fit(dlist)\n","tt = kmeans.predict(dlist)\n","comp_mat = [[0 for j in range(len(classes))] for i in range(len(classes))]\n","for i in range(N):\n","  comp_mat[tt[i]][classes[y[i]]] += 1\n","\n","best = [0,0,0]\n","for i in range(len(classes)):\n","  bst = 0\n","  for j in range(len(classes)):\n","    if(comp_mat[i][j] > bst):\n","      best[i] = j\n","      bst = comp_mat[i][j]\n","\n","err = 0\n","\n","original = []\n","res = []\n","\n","def draw_edge(x0, y0, x1, y1): plt.plot([x0, x1], [y0, y1], color='k', markersize = 0, alpha=0.1)\n","for i in adj_list:\n","    draw_edge(node_list[i[0]][0], node_list[i[0]][1], node_list[i[1]][0], node_list[i[1]][1])\n","\n","for i in range(N):\n","    plt.plot(node_list[i][0], node_list[i][1], marker='o', markersize=4, markeredgecolor=[\"g\",\"b\",\"r\", \"m\", \"y\", \"k\"][classes[y[i]]], markerfacecolor=[\"g\",\"b\",\"r\", \"m\", \"y\", \"k\"][best[tt[i]]])\n","    # plt.plot(node_list[i][0], node_list[i][1], marker='o', markersize=4, markeredgecolor=[\"g\",\"b\",\"r\", \"m\", \"y\", \"k\"][classes[y[i]]], markerfacecolor=[\"g\",\"b\",\"r\", \"m\", \"y\", \"k\"][classes[y[i]]])\n","    if classes[y[i]] != best[tt[i]]:\n","        err += 1\n","    original.append(classes[y[i]])\n","    res.append(best[tt[i]])\n","\n","plt.axis('equal')\n","plt.show()\n","\n","\n","\n","print(\"FDG Accuracy: \" + str(1 - err/N))\n","print(\"FDG Errors: \" + str(err))\n","\n","# K-means without FDGs\n","\n","z_kmeans = KMeans(n_clusters=3).fit(x)\n","z_tt = z_kmeans.predict(x)\n","\n","z_comp_mat = [[0 for j in range(len(classes))] for i in range(len(classes))]\n","for i in range(N):\n","  z_comp_mat[z_tt[i]][classes[y[i]]] += 1\n","\n","z_best = [0,0,0]\n","for i in range(len(classes)):\n","  bst = 0\n","  for j in range(len(classes)):\n","    if(z_comp_mat[i][j] > bst):\n","      z_best[i] = j\n","      bst = z_comp_mat[i][j]\n","\n","z_err = 0\n","\n","z_original = []\n","z_res = []\n","\n","for i in range(N):\n","    if classes[y[i]] != z_best[z_tt[i]]:\n","        z_err += 1\n","    z_original.append(classes[y[i]])\n","    z_res.append(z_best[z_tt[i]])\n","  \n","print(\"Stock K-Means Accuracy: \" + str(1 - z_err/N))\n","print(\"Stock K-Means Errors: \" + str(z_err))\n","\n","conf_matrix = metrics.confusion_matrix(y_true=original, y_pred=res)\n","\n","fig, ax = plt.subplots(figsize=(5, 5))\n","ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n","for i in range(conf_matrix.shape[0]):\n","    for j in range(conf_matrix.shape[1]):\n","        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n"," \n","plt.xlabel('Predictions', fontsize=18)\n","plt.ylabel('Actuals', fontsize=18)\n","plt.title('Confusion Matrix', fontsize=18)\n","plt.show()\n","print(metrics.classification_report(original, res, digits=3))\n","\n","\n","print('FDG Silhouetter Score: %.3f' % metrics.silhouette_score(X=node_list, labels=kmeans.labels_, metric='euclidean'))\n","print('FDG Davies-Bouldin Index: %.3f' % metrics.davies_bouldin_score(X=node_list, labels=kmeans.labels_))\n","\n","print('Stock K-Means Silhouetter Score: %.3f' % metrics.silhouette_score(X=x, labels=z_kmeans.labels_, metric='euclidean'))\n","print('Stock K-Means Davies-Bouldin Index: %.3f' % metrics.davies_bouldin_score(X=x, labels=z_kmeans.labels_))\n","\n","conf_matrix = metrics.confusion_matrix(y_true=z_original, y_pred=z_res)\n","\n","fig, ax = plt.subplots(figsize=(5, 5))\n","ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n","for i in range(conf_matrix.shape[0]):\n","    for j in range(conf_matrix.shape[1]):\n","        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n","\n","print(metrics.classification_report(z_original, z_res, digits=3))"]}]}